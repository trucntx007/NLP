{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StockPrediction_SentimentAnalysis.ipynb","provenance":[],"authorship_tag":"ABX9TyNMVxAxZqlNXMheEccl9gw/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2roBDvi2jNu","executionInfo":{"status":"ok","timestamp":1638414460068,"user_tz":360,"elapsed":1550,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"068fde74-3c78-47f9-b287-801eca5689b2"},"source":["import numpy as np\n","import pandas as pd\n","from nltk.classify import NaiveBayesClassifier\n","from nltk.corpus import subjectivity\n","from nltk.sentiment import SentimentAnalyzer\n","from nltk.sentiment.util import *\n","import matplotlib.pyplot as mlpt"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"]}]},{"cell_type":"code","metadata":{"id":"QUj2RmPD2vBs","executionInfo":{"status":"ok","timestamp":1638414460273,"user_tz":360,"elapsed":210,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["import tweepy\n","import csv\n","import pandas as pd\n","import random\n","import numpy as np\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"up_k4lj5Jfms"},"source":["# News Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtBxkD_s2z2s","executionInfo":{"status":"ok","timestamp":1638414460997,"user_tz":360,"elapsed":734,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"2c2d71ba-d970-40ce-9426-2be6dac20295"},"source":["# import data\n","url = 'https://raw.githubusercontent.com/trucntx007/NLP/data/stockerbot-export.csv'\n","df = pd.read_csv(url, error_bad_lines=False)\n","\n","df.info()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 28264 entries, 0 to 28263\n","Data columns (total 8 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   id             28264 non-null  int64 \n"," 1   text           28264 non-null  object\n"," 2   timestamp      28264 non-null  object\n"," 3   source         28264 non-null  object\n"," 4   symbols        28264 non-null  object\n"," 5   company_names  28263 non-null  object\n"," 6   url            21895 non-null  object\n"," 7   verified       28264 non-null  bool  \n","dtypes: bool(1), int64(1), object(6)\n","memory usage: 1.5+ MB\n"]},{"output_type":"stream","name":"stderr","text":["b'Skipping line 731: expected 8 fields, saw 13\\nSkipping line 2836: expected 8 fields, saw 15\\nSkipping line 3058: expected 8 fields, saw 12\\nSkipping line 3113: expected 8 fields, saw 12\\nSkipping line 3194: expected 8 fields, saw 17\\nSkipping line 3205: expected 8 fields, saw 17\\nSkipping line 3255: expected 8 fields, saw 17\\nSkipping line 3520: expected 8 fields, saw 17\\nSkipping line 4078: expected 8 fields, saw 17\\nSkipping line 4087: expected 8 fields, saw 17\\nSkipping line 4088: expected 8 fields, saw 17\\nSkipping line 4499: expected 8 fields, saw 12\\n'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"40lZ2ZX7S2UV","executionInfo":{"status":"ok","timestamp":1638414461001,"user_tz":360,"elapsed":16,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"bc277abe-b914-4dd4-94ed-b61edb438672"},"source":["df.sample(10).head(5)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>timestamp</th>\n","      <th>source</th>\n","      <th>symbols</th>\n","      <th>company_names</th>\n","      <th>url</th>\n","      <th>verified</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3814</th>\n","      <td>1017485603582238700</td>\n","      <td>Firstenergy Corp $FE Stock Value Rose While Th...</td>\n","      <td>Thu Jul 12 19:07:26 +0000 2018</td>\n","      <td>reurope_stock</td>\n","      <td>FE</td>\n","      <td>FirstEnergy Corp.</td>\n","      <td>https://reurope.com/2018/07/12/firstenergy-cor...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>26595</th>\n","      <td>1019696729602474000</td>\n","      <td>Copy lucrative traders automatically with Bitc...</td>\n","      <td>Wed Jul 18 21:33:40 +0000 2018</td>\n","      <td>msarybsarstee</td>\n","      <td>ETN</td>\n","      <td>Eaton Corporation plc</td>\n","      <td>https://1broker.com/?r=25023</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>25884</th>\n","      <td>1019684122099216400</td>\n","      <td>https://t.co/0mvtSFNitP  #Nadella has done a g...</td>\n","      <td>Wed Jul 18 20:43:34 +0000 2018</td>\n","      <td>paranjpe12</td>\n","      <td>MSFT</td>\n","      <td>Microsoft Corporation</td>\n","      <td>https://www.cnbc.com/2018/07/17/how-microsoft-...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>23710</th>\n","      <td>1019639090340229100</td>\n","      <td>$TMK New Insider Filing On:  LUTEK BEN Transac...</td>\n","      <td>Wed Jul 18 17:44:37 +0000 2018</td>\n","      <td>filing_scanner</td>\n","      <td>TMK</td>\n","      <td>Torchmark Corporation</td>\n","      <td>http://www.filingscanner.com/Alerts/TMK.php</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11429</th>\n","      <td>1018955475914764300</td>\n","      <td>$BA $JPM $EOG $GS $ORCL $BAC $V $EL $SPB $ACN ...</td>\n","      <td>Mon Jul 16 20:28:11 +0000 2018</td>\n","      <td>teresaarthur66</td>\n","      <td>UTX</td>\n","      <td>United Technologies Corporation</td>\n","      <td>https://twitter.com/i/web/status/1018955475914...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        id  ... verified\n","3814   1017485603582238700  ...    False\n","26595  1019696729602474000  ...    False\n","25884  1019684122099216400  ...    False\n","23710  1019639090340229100  ...    False\n","11429  1018955475914764300  ...    False\n","\n","[5 rows x 8 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"p-anZJu86p24"},"source":["# News Data Prep"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PadTtbbPBwqM","executionInfo":{"status":"ok","timestamp":1638414461875,"user_tz":360,"elapsed":887,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"625dcb1a-3706-44ac-e78c-2e4e8ad63de5"},"source":["# Removing special characters\n","\n","import re\n","import copy\n","\n","#df_cleaned = pd.DataFrame(columns=['timestamp','text'])\n","df_cleaned = df[['timestamp','text', 'symbols']]\n","\n","spec_cha = \"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"\n","#spec_cha = '[^A-Za-z0-9]+'\n","\n","\n","df_cleaned['text'] = df_cleaned['text'].replace(to_replace=spec_cha, regex=True, value=' ')\n","df_cleaned['text'].reset_index(drop=True)\n","#df_cleaned = [df_cleaned['text'].replace(spec_cha, ' ')]\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  del sys.path[0]\n"]},{"output_type":"execute_result","data":{"text/plain":["0        VIDEO   I was in my office  I was minding my o...\n","1        The price of lumber  LB F is down 22  since hi...\n","2                   Who says the American Dream is dead   \n","3        Barry Silbert is extremely optimistic on bitco...\n","4        How satellites avoid attacks and space junk wh...\n","                               ...                        \n","28259            FB   29234a9c 7f08 4d5a 985f cb1a5554ecf9\n","28260                                              BTC    \n","28261    RT  invest in hd   Nuff said    TEL  telcoin  ...\n","28262                                              BTC    \n","28263    Stellar  XLM price   0 297852 Binance registra...\n","Name: text, Length: 28264, dtype: object"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WsAc76k7-eL","executionInfo":{"status":"ok","timestamp":1638414468232,"user_tz":360,"elapsed":6360,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"0c487bb8-1b08-4794-8691-23d9018fb9aa"},"source":["# get datetime from timestamp\n","df_cleaned['datetime'] = pd.to_datetime(df['timestamp']).apply(lambda x: x.date())\n","\n","# sort by 'symbols', 'datetime'\n","df_cleaned = df_cleaned.sort_values(['symbols', 'datetime'])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"N0o_nIR29Mo-","executionInfo":{"status":"ok","timestamp":1638414468233,"user_tz":360,"elapsed":22,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"f090d035-d67e-412c-af92-58b80355fd95"},"source":["df_cleaned.head(10)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>text</th>\n","      <th>symbols</th>\n","      <th>datetime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11882</th>\n","      <td>Mon Jul 16 23:54:50 +0000 2018</td>\n","      <td>a pa  ion du football  tait d j  connue</td>\n","      <td>A</td>\n","      <td>2018-07-16</td>\n","    </tr>\n","    <tr>\n","      <th>11903</th>\n","      <td>Tue Jul 17 00:04:26 +0000 2018</td>\n","      <td>RT  ShaneOliverAMP  EZ shares  0 2  US shares ...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>11981</th>\n","      <td>Tue Jul 17 00:45:27 +0000 2018</td>\n","      <td>The geometric  R  matrix for affine crystals o...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12026</th>\n","      <td>Tue Jul 17 01:14:22 +0000 2018</td>\n","      <td>I  AM  ONE  EXAM  BAM   IT  CRY  OUT  HUBS  A...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12068</th>\n","      <td>Tue Jul 17 01:44:22 +0000 2018</td>\n","      <td>ACE  A  FIG  CRY  TOO  BIG  I  AM  MS  PEN  T...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12201</th>\n","      <td>Tue Jul 17 02:56:35 +0000 2018</td>\n","      <td>The only good moment on tonight s  raw     a ha</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12218</th>\n","      <td>Tue Jul 17 03:11:54 +0000 2018</td>\n","      <td>nicoleyyy17 m4R M1nG    4m   p     A    0r</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12224</th>\n","      <td>Tue Jul 17 03:14:38 +0000 2018</td>\n","      <td>MY  INN  ATE  A  RACE  AT  A  KING  STAY  TEN...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12259</th>\n","      <td>Tue Jul 17 03:41:26 +0000 2018</td>\n","      <td>RT  freshagenda2013  OK so maybe you re not as...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>12309</th>\n","      <td>Tue Jul 17 04:14:20 +0000 2018</td>\n","      <td>IM  OUT  A  GAS  I  ACE  ALL  KEYS  AGO  DATA...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            timestamp  ...    datetime\n","11882  Mon Jul 16 23:54:50 +0000 2018  ...  2018-07-16\n","11903  Tue Jul 17 00:04:26 +0000 2018  ...  2018-07-17\n","11981  Tue Jul 17 00:45:27 +0000 2018  ...  2018-07-17\n","12026  Tue Jul 17 01:14:22 +0000 2018  ...  2018-07-17\n","12068  Tue Jul 17 01:44:22 +0000 2018  ...  2018-07-17\n","12201  Tue Jul 17 02:56:35 +0000 2018  ...  2018-07-17\n","12218  Tue Jul 17 03:11:54 +0000 2018  ...  2018-07-17\n","12224  Tue Jul 17 03:14:38 +0000 2018  ...  2018-07-17\n","12259  Tue Jul 17 03:41:26 +0000 2018  ...  2018-07-17\n","12309  Tue Jul 17 04:14:20 +0000 2018  ...  2018-07-17\n","\n","[10 rows x 4 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"sVky6sW3TaEq","executionInfo":{"status":"ok","timestamp":1638414468233,"user_tz":360,"elapsed":17,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# new dataframe to house combined text\n","# text of the same company (same symbol) on a same date will be groupped together\n","\n","df_cleaned1 = pd.DataFrame(columns=['datetime','text','symbols'])\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"R5xNokw9Tv3R","executionInfo":{"status":"ok","timestamp":1638414476131,"user_tz":360,"elapsed":7915,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# grouping text that have the same symbol to one row\n","# then group by date\n","indx=0\n","get_tweet=\"\"\n","for i in range(0,len(df_cleaned)-1):\n","    get_date = df_cleaned['datetime'].iloc[i]\n","    next_date = df_cleaned['datetime'].iloc[i+1]\n","\n","    get_symbols = df_cleaned['symbols'].iloc[i]\n","    next_symbols = df_cleaned['symbols'].iloc[i+1]\n","\n","    if(str(get_symbols) == str(next_symbols)): \n","      if(str(get_date) != str(next_date)):\n","        get_tweet = df_cleaned['text'].iloc[i]\n","\n","        temp_df = pd.DataFrame([[get_date, get_tweet, get_symbols]]\n","                               , columns = ['Date','text','symbols'])  \n","        df_cleaned1 = pd.concat([df_cleaned1, temp_df], axis = 0).reset_index(drop = True)\n","        \n","        get_tweet=\" \"\n","      else:\n","        get_tweet = get_tweet + df_cleaned['text'].iloc[i]+\" \"\n","    else: \n","      #if (str(get_date) != str(next_date)):\n","      temp_df = pd.DataFrame([[get_date, get_tweet, get_symbols]]\n","                               , columns = ['Date','text','symbols'])\n","      df_cleaned1 = pd.concat([df_cleaned1, temp_df], axis = 0).reset_index(drop = True)\n","      get_tweet=\" \""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"YhW2vtgwlvJD","executionInfo":{"status":"ok","timestamp":1638414476134,"user_tz":360,"elapsed":18,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"06018122-1a52-4806-9b82-86ac9dd6bf4f"},"source":["df_cleaned1"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>text</th>\n","      <th>symbols</th>\n","      <th>Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>a pa  ion du football  tait d j  connue</td>\n","      <td>A</td>\n","      <td>2018-07-16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>A repeat of 2002  Walmart may be looking to...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>ACE  OUT  A  CGI  HE  PAY  ALL  DATA  YELP  ...</td>\n","      <td>A</td>\n","      <td>2018-07-18</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>myhedghog Yeah I saw  AABA was selling roughl...</td>\n","      <td>AABA</td>\n","      <td>2018-07-11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>BABA  YAHOY  AABA</td>\n","      <td>AABA</td>\n","      <td>2018-07-12</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2303</th>\n","      <td>NaN</td>\n","      <td>Zoetis Inc  ZTS Given Average Rating of  Buy  ...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-15</td>\n","    </tr>\n","    <tr>\n","      <th>2304</th>\n","      <td>NaN</td>\n","      <td>Scan results   MACD Bearish Centerline Cross t...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-16</td>\n","    </tr>\n","    <tr>\n","      <th>2305</th>\n","      <td>NaN</td>\n","      <td>ZTS Zoetis Inc  SEC Filing  Form 4</td>\n","      <td>ZTS</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>2306</th>\n","      <td>NaN</td>\n","      <td>ZTS New Insider Filing On   Fenton Andrew Tr...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-18</td>\n","    </tr>\n","    <tr>\n","      <th>2307</th>\n","      <td>NaN</td>\n","      <td>When you try to gauge sentiment on a  ticker b...</td>\n","      <td>ticker</td>\n","      <td>2018-07-12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2308 rows × 4 columns</p>\n","</div>"],"text/plain":["     datetime  ...        Date\n","0         NaN  ...  2018-07-16\n","1         NaN  ...  2018-07-17\n","2         NaN  ...  2018-07-18\n","3         NaN  ...  2018-07-11\n","4         NaN  ...  2018-07-12\n","...       ...  ...         ...\n","2303      NaN  ...  2018-07-15\n","2304      NaN  ...  2018-07-16\n","2305      NaN  ...  2018-07-17\n","2306      NaN  ...  2018-07-18\n","2307      NaN  ...  2018-07-12\n","\n","[2308 rows x 4 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"wFvupwSSVPI6","executionInfo":{"status":"ok","timestamp":1638414476134,"user_tz":360,"elapsed":16,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# drop 'datetime' column since already created 'Date'\n","df_cleaned1 = df_cleaned1.dropna(axis=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"lxGkLPvxrHNw","executionInfo":{"status":"ok","timestamp":1638414476415,"user_tz":360,"elapsed":11,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"779fa033-c3b8-4026-f8b3-720b9ed2a3a9"},"source":["# df_cleaned1 has tweets groupby symbols and Date\n","df_cleaned1.sort_values('symbols')"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>symbols</th>\n","      <th>Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a pa  ion du football  tait d j  connue</td>\n","      <td>A</td>\n","      <td>2018-07-16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A repeat of 2002  Walmart may be looking to...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ACE  OUT  A  CGI  HE  PAY  ALL  DATA  YELP  ...</td>\n","      <td>A</td>\n","      <td>2018-07-18</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Head To Head Analysis  Unisys  UIS and Altaba...</td>\n","      <td>AABA</td>\n","      <td>2018-07-18</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Today s million dollar PUT  options trade   AM...</td>\n","      <td>AABA</td>\n","      <td>2018-07-16</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2299</th>\n","      <td>Analyst   portfolio manager hunting ideas  Her...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-11</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>Abaxis  ABAX  and Zoetis Merger Deal Crosses H...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-10</td>\n","    </tr>\n","    <tr>\n","      <th>2306</th>\n","      <td>ZTS New Insider Filing On   Fenton Andrew Tr...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-18</td>\n","    </tr>\n","    <tr>\n","      <th>2301</th>\n","      <td>ZTS the bull pattern is confirmed  amp  a BUY...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-13</td>\n","    </tr>\n","    <tr>\n","      <th>2307</th>\n","      <td>When you try to gauge sentiment on a  ticker b...</td>\n","      <td>ticker</td>\n","      <td>2018-07-12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2308 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                   text symbols        Date\n","0           a pa  ion du football  tait d j  connue           A  2018-07-16\n","1        A repeat of 2002  Walmart may be looking to...       A  2018-07-17\n","2       ACE  OUT  A  CGI  HE  PAY  ALL  DATA  YELP  ...       A  2018-07-18\n","10     Head To Head Analysis  Unisys  UIS and Altaba...    AABA  2018-07-18\n","8     Today s million dollar PUT  options trade   AM...    AABA  2018-07-16\n","...                                                 ...     ...         ...\n","2299  Analyst   portfolio manager hunting ideas  Her...     ZTS  2018-07-11\n","2298  Abaxis  ABAX  and Zoetis Merger Deal Crosses H...     ZTS  2018-07-10\n","2306    ZTS New Insider Filing On   Fenton Andrew Tr...     ZTS  2018-07-18\n","2301   ZTS the bull pattern is confirmed  amp  a BUY...     ZTS  2018-07-13\n","2307  When you try to gauge sentiment on a  ticker b...  ticker  2018-07-12\n","\n","[2308 rows x 3 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"MG9Root-CX0I","executionInfo":{"status":"ok","timestamp":1638414476415,"user_tz":360,"elapsed":9,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# Split timestamp\n","# df_cleaned['timestamp'] = pd.to_datetime(df_cleaned['timestamp'],format='%Y-%m-%d')\n","\n","# df_cleaned[['dayofweek','month','day','time','timezone', 'year']] = df_cleaned.timestamp.str.split(expand=True)\n","# df_cleaned[['hour','minute','second']] = df_cleaned.time.str.split(':',expand=True)\n","\n","# df_cleaned['datetime'] = df_cleaned[['year', 'month', 'day']].agg('-'.join, axis=1)\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hHgYjqnKI_k2"},"source":["# Stock Data"]},{"cell_type":"code","metadata":{"id":"_8rhDuEHI-F7","executionInfo":{"status":"ok","timestamp":1638414476623,"user_tz":360,"elapsed":216,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["stocks = pd.read_csv('https://raw.githubusercontent.com/trucntx007/NLP/main/stocks_cleaned.csv')\n","# Define the ticker list\n","\n","tickers_list = []\n","\n","for i in range(len(stocks)):\n","  tickers = stocks['ticker'][i]\n","  tickers_list.append(tickers)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"QByk1S29rUho"},"source":["tickers_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwAzQGGctxOC","executionInfo":{"status":"ok","timestamp":1638414482372,"user_tz":360,"elapsed":5753,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"57a12253-0625-4883-a639-d3fe31cd76c1"},"source":["!pip install yfinance"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting yfinance\n","  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n","Collecting lxml>=4.5.1\n","  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n","Installing collected packages: lxml, yfinance\n","  Attempting uninstall: lxml\n","    Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","Successfully installed lxml-4.6.4 yfinance-0.1.67\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3ngFT6Ttdc7","executionInfo":{"status":"ok","timestamp":1638414544084,"user_tz":360,"elapsed":61715,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"7be692ac-07df-4bf6-fd5f-fead39811a2b"},"source":["# Fetch data from Yahoo Finance\n","import yfinance as yf\n","\n","data = yf.download(tickers_list, start='2018-7-9',end='2018-7-19')['Adj Close']\n","\n","# Drop cols with no data\n","data = data.dropna(axis=1)\n","\n","# Print first 5 rows of the data\n","print(data.head())\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[*********************100%***********************]  583 of 583 completed\n","\n","65 Failed downloads:\n","- VAR: No data found, symbol may be delisted\n","- AMTD: No data found, symbol may be delisted\n","- GG: No data found, symbol may be delisted\n","- TMK: No data found, symbol may be delisted\n","- SPN: No data found, symbol may be delisted\n","- AGN: No data found, symbol may be delisted\n","- WYN: No data found for this date range, symbol may be delisted\n","- DPS: No data found for this date range, symbol may be delisted\n","- CHK: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- HCP: No data found for this date range, symbol may be delisted\n","- RTN: No data found, symbol may be delisted\n","- CTL: No data found, symbol may be delisted\n","- GGP: No data found for this date range, symbol may be delisted\n","- LUK: No data found for this date range, symbol may be delisted\n","- S: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- GLUU: No data found, symbol may be delisted\n","- FOXA: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- HTZ: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- ABX: No data found for this date range, symbol may be delisted\n","- LB: No data found, symbol may be delisted\n","- MON: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- JEC: No data found, symbol may be delisted\n","- CY: No data found, symbol may be delisted\n","- MYL: No data found, symbol may be delisted\n","- DLPH: No data found, symbol may be delisted\n","- AABA: No data found, symbol may be delisted\n","- AKS: No data found, symbol may be delisted\n","- FLIR: No data found, symbol may be delisted\n","- WFT: No data found, symbol may be delisted\n","- CXO: No data found, symbol may be delisted\n","- FNSR: No data found, symbol may be delisted\n","- APC: No data found, symbol may be delisted\n","- SYMC: No data found, symbol may be delisted\n","- ALXN: No data found, symbol may be delisted\n","- ETFC: No data found, symbol may be delisted\n","- MNK: No data found, symbol may be delisted\n","- FOX: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- TWX: No data found for this date range, symbol may be delisted\n","- BBT: No data found, symbol may be delisted\n","- ARRY: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- CBS: No data found, symbol may be delisted\n","- HDS: No data found, symbol may be delisted\n","- ESV: No data found, symbol may be delisted\n","- CRZO: No data found, symbol may be delisted\n","- HRS: No data found, symbol may be delisted\n","- VIAB: No data found, symbol may be delisted\n","- PAH: No data found for this date range, symbol may be delisted\n","- RHT: No data found, symbol may be delisted\n","- FMSA: No data found for this date range, symbol may be delisted\n","- DCIX: No data found, symbol may be delisted\n","- XL: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- BHGE: No data found, symbol may be delisted\n","- TIF: No data found, symbol may be delisted\n","- CELG: No data found, symbol may be delisted\n","- ETE: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- ARNC: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- WPX: No data found, symbol may be delisted\n","- JCP: No data found, symbol may be delisted\n","- UTX: No data found, symbol may be delisted\n","- NBL: No data found, symbol may be delisted\n","- STI: No data found, symbol may be delisted\n","- TSS: No data found, symbol may be delisted\n","- PX: Data doesn't exist for startDate = 1531094400, endDate = 1531958400\n","- VRX: No data found for this date range, symbol may be delisted\n","- KORS: None\n","                    A        AAL       AAOI  ...       ZION  ZNGA        ZTS\n","Date                                         ...                            \n","2018-07-09  61.546665  38.477581  45.330002  ...  48.723938  4.24  85.723831\n","2018-07-10  62.082947  38.291603  45.790001  ...  48.263168  4.19  84.479462\n","2018-07-11  61.293140  35.198521  45.759998  ...  48.001163  4.26  82.794174\n","2018-07-12  61.868435  35.560684  48.799999  ...  47.477158  4.40  83.744606\n","2018-07-13  61.800171  36.333954  47.779999  ...  46.763416  4.34  84.401085\n","\n","[5 rows x 518 columns]\n"]}]},{"cell_type":"code","metadata":{"id":"DqlkLAv0HkBQ","executionInfo":{"status":"ok","timestamp":1638414544084,"user_tz":360,"elapsed":15,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# add column datetime\n","data[data.index.name] = data.index"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PJMfLDCC_2a","executionInfo":{"status":"ok","timestamp":1638414544085,"user_tz":360,"elapsed":5,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# Transpose stock dataset\n","data_T = data\n","data_T = data_T.transpose()\n","data_T['symbols'] = data_T.index"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"0PhbW01TDKhP","executionInfo":{"status":"ok","timestamp":1638414544220,"user_tz":360,"elapsed":140,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"3cd23f7a-ac97-4af4-a472-07afb2662e6f"},"source":["# price of a stock during the period\n","data_Tr = data_T.melt(id_vars=['symbols'],var_name=\"Date\", value_name='Price')\n","data_Tr.sort_values(['symbols', 'Date'])"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>symbols</th>\n","      <th>Date</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>2018-07-09</td>\n","      <td>61.5467</td>\n","    </tr>\n","    <tr>\n","      <th>519</th>\n","      <td>A</td>\n","      <td>2018-07-10</td>\n","      <td>62.0829</td>\n","    </tr>\n","    <tr>\n","      <th>1038</th>\n","      <td>A</td>\n","      <td>2018-07-11</td>\n","      <td>61.2931</td>\n","    </tr>\n","    <tr>\n","      <th>1557</th>\n","      <td>A</td>\n","      <td>2018-07-12</td>\n","      <td>61.8684</td>\n","    </tr>\n","    <tr>\n","      <th>2076</th>\n","      <td>A</td>\n","      <td>2018-07-13</td>\n","      <td>61.8002</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2074</th>\n","      <td>ZTS</td>\n","      <td>2018-07-12</td>\n","      <td>83.7446</td>\n","    </tr>\n","    <tr>\n","      <th>2593</th>\n","      <td>ZTS</td>\n","      <td>2018-07-13</td>\n","      <td>84.4011</td>\n","    </tr>\n","    <tr>\n","      <th>3112</th>\n","      <td>ZTS</td>\n","      <td>2018-07-16</td>\n","      <td>82.8726</td>\n","    </tr>\n","    <tr>\n","      <th>3631</th>\n","      <td>ZTS</td>\n","      <td>2018-07-17</td>\n","      <td>84.0385</td>\n","    </tr>\n","    <tr>\n","      <th>4150</th>\n","      <td>ZTS</td>\n","      <td>2018-07-18</td>\n","      <td>84.2149</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4152 rows × 3 columns</p>\n","</div>"],"text/plain":["     symbols       Date    Price\n","0          A 2018-07-09  61.5467\n","519        A 2018-07-10  62.0829\n","1038       A 2018-07-11  61.2931\n","1557       A 2018-07-12  61.8684\n","2076       A 2018-07-13  61.8002\n","...      ...        ...      ...\n","2074     ZTS 2018-07-12  83.7446\n","2593     ZTS 2018-07-13  84.4011\n","3112     ZTS 2018-07-16  82.8726\n","3631     ZTS 2018-07-17  84.0385\n","4150     ZTS 2018-07-18  84.2149\n","\n","[4152 rows x 3 columns]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"HnN7MDT-xW5r","executionInfo":{"status":"ok","timestamp":1638414544223,"user_tz":360,"elapsed":19,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# get list of symbols\n","tickers_list = pd.Series(data_Tr['symbols'].unique())\n","tickers_list.to_csv('tickerlist.csv')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"P18kKk0WvB_a","executionInfo":{"status":"ok","timestamp":1638414544226,"user_tz":360,"elapsed":21,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# save stock prices to StockData.csv\n","data.to_csv('StockData.csv')"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cb-h_-BqAb4U"},"source":["# Combine datasets"]},{"cell_type":"code","metadata":{"id":"SOY84PAoAtMR","executionInfo":{"status":"ok","timestamp":1638414544227,"user_tz":360,"elapsed":22,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}}},"source":["# add column 'Price' to df_cleaned1\n","df_cleaned1['Price'] = ''"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"vRkpBGt6H94C","executionInfo":{"status":"ok","timestamp":1638414544228,"user_tz":360,"elapsed":23,"user":{"displayName":"Truc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01695833024010148463"}},"outputId":"9e9fee39-9c73-403b-8a5f-fe07c4767090"},"source":["df_cleaned1.sort_values('symbols')"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>symbols</th>\n","      <th>Date</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a pa  ion du football  tait d j  connue</td>\n","      <td>A</td>\n","      <td>2018-07-16</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A repeat of 2002  Walmart may be looking to...</td>\n","      <td>A</td>\n","      <td>2018-07-17</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ACE  OUT  A  CGI  HE  PAY  ALL  DATA  YELP  ...</td>\n","      <td>A</td>\n","      <td>2018-07-18</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Head To Head Analysis  Unisys  UIS and Altaba...</td>\n","      <td>AABA</td>\n","      <td>2018-07-18</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Today s million dollar PUT  options trade   AM...</td>\n","      <td>AABA</td>\n","      <td>2018-07-16</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2299</th>\n","      <td>Analyst   portfolio manager hunting ideas  Her...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-11</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>Abaxis  ABAX  and Zoetis Merger Deal Crosses H...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-10</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2306</th>\n","      <td>ZTS New Insider Filing On   Fenton Andrew Tr...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-18</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2301</th>\n","      <td>ZTS the bull pattern is confirmed  amp  a BUY...</td>\n","      <td>ZTS</td>\n","      <td>2018-07-13</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2307</th>\n","      <td>When you try to gauge sentiment on a  ticker b...</td>\n","      <td>ticker</td>\n","      <td>2018-07-12</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2308 rows × 4 columns</p>\n","</div>"],"text/plain":["                                                   text  ... Price\n","0           a pa  ion du football  tait d j  connue      ...      \n","1        A repeat of 2002  Walmart may be looking to...  ...      \n","2       ACE  OUT  A  CGI  HE  PAY  ALL  DATA  YELP  ...  ...      \n","10     Head To Head Analysis  Unisys  UIS and Altaba...  ...      \n","8     Today s million dollar PUT  options trade   AM...  ...      \n","...                                                 ...  ...   ...\n","2299  Analyst   portfolio manager hunting ideas  Her...  ...      \n","2298  Abaxis  ABAX  and Zoetis Merger Deal Crosses H...  ...      \n","2306    ZTS New Insider Filing On   Fenton Andrew Tr...  ...      \n","2301   ZTS the bull pattern is confirmed  amp  a BUY...  ...      \n","2307  When you try to gauge sentiment on a  ticker b...  ...      \n","\n","[2308 rows x 4 columns]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"ip4pA_pKA0Yy"},"source":["# append 'Price' from Stock Dataset to News Dataset\n","for i in range (0,len(df_cleaned1)):\n","    for j in range (0,len(data_Tr)):\n","        get_tweet_date = df_cleaned1['Date'].iloc[i]\n","        get_stock_date = (data_Tr['Date'].iloc[j]).date() # get rid of 00:00:00\n","        \n","        get_tweet_symbol = df_cleaned1['symbols'].iloc[i]\n","        get_stock_symbol = data_Tr['symbols'].iloc[j]\n","\n","        if(str(get_tweet_symbol) == str(get_stock_symbol) and \n","           (str(get_stock_date) == str(get_tweet_date))):\n","            #print(get_stock_date,\" \",get_tweet_date)\n","            df_cleaned1['Price'].iloc[i] = int(data_Tr['Price'][j])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2jmq4co0SrP"},"source":["# fill missing 'Price' with the most recent price\n","for i in range(len(df_cleaned1)):\n","  if df_cleaned1['Price'].iloc[i] == '':\n","    df_cleaned1['Price'].iloc[i] = df_cleaned1['Price'].iloc[i-1] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHP2qgbmP1hH"},"source":["combined_data = df_cleaned1\n","combined_data.to_csv('combined_data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcnPXyegrzrw"},"source":["# convert 'Price' to integer\n","combined_data['Price'] = combined_data['Price'].apply(np.int64)\n","\n","# adding columns for sentiment analysis\n","combined_data['Emotion'] = ''\n","combined_data['Negative'] = ''\n","combined_data['Neutral'] = ''\n","combined_data['Positive'] = ''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnTSJmx53GjT"},"source":["# Sentiment Analysis with vader\n","import nltk\n","nltk.download('vader_lexicon')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlU4B2Ei3RtB"},"source":["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import unicodedata\n","sentiment_i_a = SentimentIntensityAnalyzer()\n","for indexx, row in combined_data.T.iteritems():\n","    try:\n","        sentence_i = unicodedata.normalize('NFKD', combined_data.loc[indexx, 'text'])\n","        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n","        combined_data['Emotion'].iloc[indexx] = sentence_sentiment['compound']\n","        combined_data['Negative'].iloc[indexx] = sentence_sentiment['neg']\n","        combined_data['Neutral'].iloc[indexx] = sentence_sentiment['neu']\n","        combined_data['Positive'].iloc[indexx] = sentence_sentiment['compound']\n","        \n","    except TypeError:\n","        print (stocks_dataf.loc[indexx, 'text'])\n","        print (indexx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip6GU_1T4SD-"},"source":["combined_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYcD2EzyM-Bw"},"source":["# NLP Text Processing"]},{"cell_type":"code","metadata":{"id":"s6z8dSQnNLtY"},"source":["import re\n","import nltk\n","import ssl\n"," \n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import RegexpTokenizer\n","nltk.download('wordnet') \n","from nltk.stem.wordnet import WordNetLemmatizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvTZdKv3PisD"},"source":["!pip install langdetect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3lDr9pNNSif"},"source":["# Remove Stop words\n","freq = pd.Series(' '.join(df_cleaned['text']).lower().split()).value_counts()[:20]\n","freq\n","\n","stop_words = set(stopwords.words(\"english\"))\n","stop_words = stop_words.union(freq.index.tolist())\n","extra_words = ['amp', 'rt']\n","stop_words = stop_words.union(extra_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2JEmukFPvfb"},"source":["# Processing language \n","\n","from langdetect import detect_langs\n","\n","#check for valid string only to detect languages\n","TextValid=[]\n","\n","for i in range(len(df_cleaned)):\n","    TextValid.append(bool(re.match('^(?=.*[a-zA-Z])', df_cleaned.iloc[i,0])))\n","    \n","df_cleaned['valid'] = TextValid\n","#print(len(df_cleaned[df_cleaned['valid']==False]))\n","#print(len(df_cleaned[df_cleaned['valid']==True]))\n","\n","# Detect languages for each text\n","languages = []\n","\n","# Loop over the sentences in the data and detect their language\n","for row in range(len(df_cleaned)):\n","    languages.append(detect_langs(df_cleaned.iloc[row, 0]))\n","    \n","languages = [str(lang).split(':')[0][1:] for lang in languages] \n","\n","# Assign the list to a new feature \n","df_cleaned['language'] = languages\n","\n","# count the languages in the data\n","df_cleaned['language'].value_counts()\n","\n","# keep EN Only\n","df_cleaned = df_cleaned[df_cleaned['language']=='en']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_4oMpHzRo8_"},"source":["df_cleaned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwpxuXVcOCie"},"source":["corpus = []\n","for i in df_cleaned.index:\n","    #Remove punctuations\n","    text = re.sub('[^a-zA-Z]', ' ', df_cleaned['text'][i])\n","    \n","    #Convert to lowercase\n","    text = text.lower()\n","    \n","    #remove tags\n","    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n","    \n","    # remove special characters and digits\n","    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n","    text = text.replace(\"\\n\",\"\")\n","   \n","    ##Convert to list from string\n","    text = text.split()\n","    \n","    ##Stemming\n","    ps=PorterStemmer()    #Lemmatisation\n","    lem = WordNetLemmatizer()\n","    text = [lem.lemmatize(word) for word in text if not word in  \n","            stop_words] \n","    df_cleaned['keywords'] = pd.Series(text)\n","    text = \" \".join(text)\n","    corpus.append(text)\n","    \n","pd.Series(corpus).sample(20).head(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZ3TTAzkJGGn"},"source":["# Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"Q0lRgCs47Wci"},"source":["!pip install flair"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4gVzmqMdX1Ws"},"source":["!pip install textblob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaR6qM5gT1Jq"},"source":["# Detect Emotions for each text Form TextBlob Library\n","from textblob import TextBlob\n","\n","detectEmotion = []\n","detectPolarity = []\n","\n","for txt in corpus:\n","    analysis = TextBlob(txt)\n","    Polarity = analysis.sentiment.polarity\n","    \n","    if Polarity < 0:\n","        emotion = '2'  #Negative\n","    elif Polarity > 0: \n","        emotion = '1'  #Positive\n","    else:\n","        emotion = '0'  #Neutral\n","        \n","    detectEmotion.append(emotion)\n","    detectPolarity.append(Polarity)\n","    \n","df_cleaned['Polarity'] = detectPolarity\n","df_cleaned['Emotion'] = detectEmotion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCzByHIFWa73"},"source":["df_cleaned.sort_values(by = ['timestamp'])\n","#jul-9-2018\n","#jul-18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzMRm45fao_V"},"source":["# Percentage of each Emotions overall symbols\n","\n","df_neutral   = df_cleaned['text'][df_cleaned['Emotion'] == '0']\n","df_positive  = df_cleaned['text'][df_cleaned['Emotion'] == '1']\n","df_negative  = df_cleaned['text'][df_cleaned['Emotion'] == '2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1khHii0a42j"},"source":["print(f'Percentage Positive: {len(df_positive)/len(df_cleaned)}')\n","print(f'Percentage Negetive: {len(df_negative)/len(df_cleaned)}')\n","print(f'Percentage Neutral: {len(df_neutral)/len(df_cleaned)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ni8yyKnKbwOJ"},"source":["# NLP Models"]},{"cell_type":"code","metadata":{"id":"jW5a7xmCbzi5"},"source":["import nltk\n","from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","from nltk import ngrams\n","from sklearn.model_selection import train_test_split\n","import time\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import svm\n","from sklearn import tree\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","\n","x_train, x_test, y_train, y_test = train_test_split(df_cleaned['text'], df_cleaned['Emotion'], test_size=0.2, random_state=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yp83__U6b82x"},"source":["# Ngram Models\n","def NgramModels(Model , txt, n):\n","    vect      = CountVectorizer(max_features=1000 , ngram_range=(n,n))\n","    train_vect= vect.fit_transform(x_train)\n","    test_vect = vect.transform(x_test)\n","    \n","    model     = Model\n","    t0        = time.time()\n","    model.fit(train_vect, y_train)\n","    t1        = time.time()\n","    predicted = model.predict(test_vect)\n","    t2        = time.time()\n","    time_train= t1-t0\n","    time_pred = t2-t1\n","    \n","    accuracy  = model.score(train_vect, y_train)\n","    predicted = model.predict(test_vect)\n","    \n","    report = classification_report(y_test, predicted, output_dict=True)\n","    print(\"Models with \" , n , \"-grams :\\n\")\n","    print('********************** \\n')\n","    print(txt)\n","    print(\"Training time: %fs; Prediction time: %fs \\n\" % (time_train, time_pred))\n","    print('Accuracy score train set :', accuracy)\n","    print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n","    print('Positive: ', report['1'])\n","    print('Neutral : ', report['0'])\n","    print('Negative: ', report['2'])\n","    print('\\n --------------------------------------------------------------------------------------------------- \\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBIsWpxOclwz"},"source":["def KNN_Ngram(n):\n","    vect      = CountVectorizer(max_features=1000 , ngram_range=(n,n))\n","    train_vect= vect.fit_transform(x_train)\n","    test_vect = vect.transform(x_test)\n","    \n","    for k in [1,3,5,7,10]:\n","        model = KNeighborsClassifier(n_neighbors=k,algorithm='brute')\n","        t0        = time.time()\n","        model.fit(train_vect, y_train)\n","        t1        = time.time()\n","        predicted = model.predict(test_vect)\n","        t2        = time.time()\n","        time_train= t1-t0\n","        time_pred = t2-t1\n","\n","        accuracy  = model.score(train_vect, y_train)\n","        predicted = model.predict(test_vect)\n","\n","        report = classification_report(y_test, predicted, output_dict=True)\n","\n","        print(\"Models with \" , n , \"-grams :\\n\")\n","        print('********************** \\n')\n","        print(\"Classification Report for k = {} is:\\n\".format(k))\n","        print(\"Training time: %fs ; Prediction time: %fs \\n\" % (time_train, time_pred))\n","        print('Accuracy score train set :', accuracy)\n","        print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n","        print('Positive: ', report['1'])\n","        print('Neutral : ', report['0'])\n","        print('Negative: ', report['2'])\n","        print('\\n -------------------------------------------------------------------------------------- \\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJcS2cEXdHFX"},"source":["def TFIDFModels(Model,txt):\n","    vect      = TfidfVectorizer(min_df = 5, max_df =0.8, sublinear_tf = True, use_idf = True)\n","    train_vect= vect.fit_transform(x_train)\n","    test_vect = vect.transform(x_test)\n","    \n","    model     = Model\n","    t0        = time.time()\n","    model.fit(train_vect, y_train)\n","    t1        = time.time()\n","    predicted = model.predict(test_vect)\n","    t2        = time.time()\n","    time_train= t1-t0\n","    time_pred = t2-t1\n","    \n","    accuracy  = model.score(train_vect, y_train)\n","    predicted = model.predict(test_vect)\n","    \n","    report = classification_report(y_test, predicted, output_dict=True)\n","    \n","    print(txt)\n","    print(\"Training time: %fs; Prediction time: %fs \\n\" % (time_train, time_pred))\n","    print('Accuracy score train set :', accuracy)\n","    print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n","    print('Positive: ', report['1'])\n","    print('Neutral : ', report['0'])\n","    print('Negative: ', report['2'])\n","    print('\\n -------------------------------------------------------------------------------------- \\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rKLeIM__dMv7"},"source":["def KNN_TFIDF():\n","    vect      = TfidfVectorizer(min_df = 5, max_df =0.8, sublinear_tf = True, use_idf = True)\n","    train_vect= vect.fit_transform(x_train)\n","    test_vect = vect.transform(x_test)\n","    \n","    for k in [1,3,5,7,10]:\n","\n","        model = KNeighborsClassifier(n_neighbors=k,algorithm='brute')\n","        t0        = time.time()\n","        model.fit(train_vect, y_train)\n","        t1        = time.time()\n","        predicted = model.predict(test_vect)\n","        t2        = time.time()\n","        time_train= t1-t0\n","        time_pred = t2-t1\n","\n","        accuracy  = model.score(train_vect, y_train)\n","        predicted = model.predict(test_vect)\n","\n","        report = classification_report(y_test, predicted, output_dict=True)\n","\n","        print(\"Classification Report for k = {} is:\\n\".format(k))\n","        print(\"Training time: %fs ; Prediction time: %fs \\n\" % (time_train, time_pred))\n","        print('Accuracy score train set :', accuracy)\n","        print('Accuracy score test set  :', accuracy_score(y_test, predicted),'\\n')\n","        print('Positive: ', report['1'])\n","        print('Neutral : ', report['0'])\n","        print('Negative: ', report['2'])\n","        print('\\n -------------------------------------------------------------------------------------- \\n')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jyxLfIgleAks"},"source":["# Train Models and Make Predictions"]},{"cell_type":"code","metadata":{"id":"_cusGiMrd_8O"},"source":["SupportVectorClassifier=svm.SVC(kernel='linear')\n","\n","LogReg2 = NgramModels(Model = LogisticRegression(),txt = '\\nLogistic Regression Model : \\n ', n=2)\n","LogReg3 = NgramModels(Model = LogisticRegression(),txt = 'Logistic Regression Model : \\n ', n=3)\n","\n","svm2 = NgramModels(Model = SupportVectorClassifier ,txt = 'Support Vectoer Classifier Model : \\n ', n=2)\n","svm3 = NgramModels(Model = SupportVectorClassifier ,txt = 'Support Vectoer Classifier Model : \\n ', n=3)\n","\n","DecTree2 = NgramModels(Model = tree.DecisionTreeClassifier(),txt = 'Decision Tree Classifier Model : \\n ', n=2)\n","DecTree3 = NgramModels(Model = tree.DecisionTreeClassifier(),txt = 'Decision Tree Classifier Model : \\n ', n=3)\n","\n","KNN2=KNN_Ngram(2)\n","KNN3=KNN_Ngram(3)\n","\n","print('Models with Tfidf Feature extraction Techniques : \\n')\n","print('************************************************ \\n')\n","\n","LogReg = TFIDFModels(Model = LogisticRegression(),txt = 'Logistic Regression Model : \\n ')\n","svm = TFIDFModels(Model = SupportVectorClassifier,txt = 'Support Vector Classifier Model : \\n ')\n","DecTree = TFIDFModels(Model = tree.DecisionTreeClassifier(),txt = 'Decision Tree Classifier Model : \\n ')\n","knn_tfidf = KNN_TFIDF()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLn9ncpXfm5c"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJnb-EZof_lG"},"source":["# Results"]},{"cell_type":"code","metadata":{"id":"8P0ZgLzTf78x"},"source":["idx = pd.MultiIndex.from_product([['2-grams', '3-grams', 'TFIDF'],['Accuracy Training %','Accuracy Testing %']],names=['FeatureExtraction', 'Metric'])\n","col = ['LogisticRegression', 'SupportVectorClassifier', 'DecisionTree', 'KNeighborsClassifier']\n","\n","Result = pd.DataFrame('*', idx, col)\n","\n","Result.LogisticRegression=['79.17','76.92','73.60','71.99','95.73','93.35']\n","Result.SupportVectorClassifier=['78.91','76.94','73.65','72.15','97.83','95.99']\n","Result.DecisionTree=['82.66','77.32','74.12','72.15','1.0','95.96']\n","Result.KNeighborsClassifier=['80.77','74.24','73.08','70.69','1.0','82.46']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flJ_miQKkgqa"},"source":["Result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3NNyZNJj7P0H"},"source":["# Stock Price Predictions using sentiment analysis"]},{"cell_type":"code","metadata":{"id":"KKCFKxywkip_"},"source":["# columns to be used for prediction\n","df_stock_val = combined_data[['Date','Price','Emotion','Negative','Neutral','Positive']].copy()\n","df_stock_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JS_XIeOM75kr"},"source":["# Split dataset for training and testing\n","x_train, x_test, y_train, y_test = train_test_split(df_stock_val['Price'], df_stock_val['Emotion'], test_size=0.2, random_state=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WID-VFOp88E1"},"source":["ls_sentiments_score = []\n","for date, row in x_train.iteritems():\n","    sentiment_score = np.asarray([combined_data.loc[date, 'Emotion']])\n","    ls_sentiments_score.append(sentiment_score)\n","numpy_dataframe_train = np.asarray(ls_sentiments_score)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-G12ngCP-7qy"},"source":["ls_sentiments_score = []\n","for date, row in x_test.iteritems():\n","    sentiment_score = np.asarray([combined_data.loc[date, 'Emotion']])\n","    ls_sentiments_score.append(sentiment_score)\n","numpy_dataframe_test = np.asarray(ls_sentiments_score)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bskJ9MR2_MuA"},"source":["from sklearn.metrics import precision_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxFrkgyW_NDH"},"source":["# from treeinterpreter import treeinterpreter as ti\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","rf = RandomForestRegressor()\n","rf.fit(numpy_dataframe_train, y_train)\n","prediction=rf.predict(numpy_dataframe_test)\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","#idx = pd.date_range(test_data_start, test_data_end)\n","predictions_df = pd.DataFrame(data=prediction[0:], columns=['Price'])\n","predictions_df['Price'] = predictions_df['Price'].apply(np.int64)\n","predictions_df['Price'] = predictions_df['Price'] + 4500\n","predictions_df['actual_value'] = y_test\n","predictions_df.columns = ['predicted_price', 'actual_price']\n","predictions_df.plot()\n","predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n","y_test = y_test.apply(np.int64)\n","#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))\n","print(rf.score(numpy_dataframe_train, y_train))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJ7B0WHD_xhf"},"source":[""],"execution_count":null,"outputs":[]}]}